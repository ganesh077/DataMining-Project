{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11675721,"sourceType":"datasetVersion","datasetId":7327880}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install required packages (uncomment if running locally)\n# !pip install scikit-learn matplotlib joblib\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom joblib import Parallel, delayed, dump\n\n# Load datasets\nchess_df = pd.read_csv('/kaggle/input/chess-dataset/chessData.csv')\nrandom_df = pd.read_csv('/kaggle/input/chess-dataset/random_evals.csv')\n\n# Clean evaluations\ndef clean_evaluations(series):\n    def to_float(val):\n        try:\n            val = str(val).strip()\n            if val.startswith(\"#\"):\n                return 10000.0 if \"+\" in val else -10000.0\n            return float(val)\n        except:\n            return np.nan\n    return series.map(to_float)\n\n# FEN to features\ndef fen_to_features(fen):\n    try:\n        fields = fen.strip().split()\n        board_str, active, castling = fields[0], fields[1], fields[2]\n    except:\n        return None\n\n    piece_counts = {c: 0 for c in 'PNBRQKpnbrqk'}\n    board_rows = board_str.split('/')\n    board_grid = []\n    for row in board_rows:\n        expanded = []\n        for ch in row:\n            if ch.isdigit():\n                expanded += ['.'] * int(ch)\n            else:\n                expanded.append(ch)\n        board_grid.append(expanded)\n\n    for row in board_grid:\n        for ch in row:\n            if ch in piece_counts:\n                piece_counts[ch] += 1\n\n    values = {'P':1,'N':3,'B':3,'R':5,'Q':9,'p':1,'n':3,'b':3,'r':5,'q':9}\n    white_mat = sum(piece_counts[c] * values[c] for c in 'PNBRQ')\n    black_mat = sum(piece_counts[c] * values[c] for c in 'pnbrq')\n    material_balance = white_mat - black_mat\n\n    def is_king_castled(color):\n        row = 7 if color == 'w' else 0\n        for col in range(8):\n            if board_grid[row][col] == ('K' if color == 'w' else 'k'):\n                return int(col in [6, 2])\n        return 0\n\n    white_king_castled = is_king_castled('w')\n    black_king_castled = is_king_castled('b')\n\n    white_pawn_ranks = [7 - i for i in range(8) for j in range(8) if board_grid[i][j] == 'P']\n    black_pawn_ranks = [i for i in range(8) for j in range(8) if board_grid[i][j] == 'p']\n    pawn_adv_white = sum(white_pawn_ranks) / len(white_pawn_ranks) if white_pawn_ranks else 2\n    pawn_adv_black = sum(black_pawn_ranks) / len(black_pawn_ranks) if black_pawn_ranks else 2\n\n    white_queen_central = any(board_grid[r][c] == 'Q' for r in range(8) for c in [3, 4])\n    black_queen_central = any(board_grid[r][c] == 'q' for r in range(8) for c in [3, 4])\n\n    center_squares = [(3,3), (3,4), (4,3), (4,4)]\n    center_control_white = sum(1 for r, c in center_squares if board_grid[r][c].isupper())\n    center_control_black = sum(1 for r, c in center_squares if board_grid[r][c].islower())\n\n    return {\n        **{f\"cnt_{p}\": piece_counts[p] for p in piece_counts},\n        \"material_balance\": material_balance,\n        \"active_white\": int(active == 'w'),\n        \"castle_wk\": int('K' in castling),\n        \"castle_wq\": int('Q' in castling),\n        \"castle_bk\": int('k' in castling),\n        \"castle_bq\": int('q' in castling),\n        \"white_king_castled\": white_king_castled,\n        \"black_king_castled\": black_king_castled,\n        \"pawn_advancement_white\": pawn_adv_white,\n        \"pawn_advancement_black\": pawn_adv_black,\n        \"queen_central_white\": int(white_queen_central),\n        \"queen_central_black\": int(black_queen_central),\n        \"center_control_white\": center_control_white,\n        \"center_control_black\": center_control_black\n    }\n\n# Parallelized preprocessing\ndef df_to_clean_feature_df_parallel(df, chunk_size=200_000, n_jobs=-1):\n    feats_list, labs_list = [], []\n    for start in range(0, len(df), chunk_size):\n        chunk = df.iloc[start:start + chunk_size]\n        fen_feats = [(i, fen_to_features(fen)) for i, fen in chunk[\"FEN\"].items()]\n        fen_feats = [(i, f) for i, f in fen_feats if f is not None]\n        if not fen_feats:\n            continue\n        indices, feature_dicts = zip(*fen_feats)\n        feats = pd.DataFrame(feature_dicts, index=indices)\n        raw_evals = chunk.loc[feats.index, \"Evaluation\"]\n        cleaned_evals = clean_evaluations(raw_evals).dropna()\n        feats = feats.loc[cleaned_evals.index]\n        feats_list.append(feats)\n        labs_list.append(cleaned_evals)\n    X = pd.concat(feats_list, ignore_index=True)\n    y = pd.concat(labs_list, ignore_index=True)\n    return X, y\n\n# Run preprocessing\nprint(\"Processing training data...\")\nX_train, y_train = df_to_clean_feature_df_parallel(chess_df)\n\nprint(\"Processing test data...\")\nX_test, y_test = df_to_clean_feature_df_parallel(random_df)\n\n# Clip and scale\ny_train = y_train.clip(-1000, 1000) / 100.0\ny_test = y_test.clip(-1000, 1000) / 100.0\n\nscaler = StandardScaler().fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Train Random Forest\nprint(\"Training RandomForestRegressor...\")\nrf_model = RandomForestRegressor(\n    n_estimators=200,\n    max_depth=15,\n    n_jobs=-1,\n    random_state=42\n)\nrf_model.fit(X_train_scaled, y_train)\nprint(\"Training complete.\")\n\n# Predict\ny_pred = rf_model.predict(X_test_scaled)\n\n# Evaluate\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nr2 = r2_score(y_test, y_pred)\naccuracy = (np.abs(y_test - y_pred) <= 1.0).mean()\n\nprint(f\"RMSE: {rmse:.2f} pawns\")\nprint(f\"R² Score: {r2:.4f}\")\nprint(f\"Accuracy within ±1 pawn: {accuracy * 100:.2f}%\")\n\n# Save model\ndump(rf_model, \"/kaggle/working/random_forest_model.joblib\")\nprint(\"Model saved to /kaggle/working/random_forest_model.joblib\")\n\n# Plot\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred, alpha=0.3, color='dodgerblue', label=\"Predicted vs Actual\")\nplt.plot([-5, 5], [-5, 5], color='red', linestyle='--', label=\"Perfect Prediction\")\nplt.xlabel(\"Stockfish Evaluation (True)\")\nplt.ylabel(\"Model Prediction\")\nplt.title(\"Random Forest Model vs Stockfish\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T02:47:09.892865Z","iopub.execute_input":"2025-05-05T02:47:09.893228Z"}},"outputs":[{"name":"stdout","text":"Processing training data...\nProcessing test data...\nTraining RandomForestRegressor...\nTraining complete.\nRMSE: 4.68 pawns\nR² Score: 0.4125\nAccuracy within ±1 pawn: 28.94%\nModel saved to /kaggle/working/random_forest_model.joblib\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  fig.canvas.print_figure(bytes_io, **kw)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}